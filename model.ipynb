{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, List\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer, pipeline\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6876890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# YAML config\n",
    "try:\n",
    "    with open(r\".\\config.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "# Logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(funcName)s - %(message)s\",\n",
    "    filename=config[\"log_dir\"] +\n",
    "    f\"{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.log\",\n",
    "    filemode=\"w\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Config file and logger setup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class\n",
    "class FoodDataset():\n",
    "    \"\"\"\n",
    "    A custom dataset class for the food image classification task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "        \"\"\"\n",
    "        self.dataset = load_dataset(config[\"dataset_path\"])\n",
    "        self.image_processor = AutoImageProcessor.from_pretrained(\n",
    "            config[\"base_model\"], use_fast=True)\n",
    "\n",
    "        try:\n",
    "            self.labels = self.dataset[\"train\"].features[\"label\"].names\n",
    "            label2id, id2label = dict(), dict()\n",
    "\n",
    "            for i, label in enumerate(self.labels):\n",
    "                label2id[label] = i\n",
    "                id2label[i] = label\n",
    "\n",
    "            self.label2id = label2id\n",
    "            self.id2label = id2label\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing labels: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single item from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the image and label.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            example = self.dataset[idx]\n",
    "            image = example[\"image\"]\n",
    "            label = example[\"label\"]\n",
    "\n",
    "            pixel_values = self.image_processor(\n",
    "                image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "            return {\"pixel_values\": pixel_values, \"label\": label}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing item at index {idx}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "food = FoodDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "def augment_images(example):\n",
    "    \"\"\"\n",
    "    Augments images with defined values.\n",
    "\n",
    "    Args:\n",
    "        example: Use over dataset\"s .with_transform() method.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        normalize = Normalize(\n",
    "            mean=food.image_processor.image_mean, std=food.image_processor.image_std)\n",
    "\n",
    "        size = (food.image_processor.size[\"shorted_edge\"]\n",
    "                if \"shorted_edge\" in food.image_processor.size\n",
    "                else (food.image_processor.size[\"height\"], food.image_processor.size[\"width\"]))\n",
    "\n",
    "        # Data augmentation\n",
    "        _transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])\n",
    "\n",
    "        example[\"pixel_values\"] = [_transforms(img.convert(\n",
    "            \"RGB\")) for img in example[\"image\"]]  # Similar to input_ids in NLP\n",
    "        del example[\"image\"]\n",
    "\n",
    "        return example\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Transform images failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_augment = food.dataset.with_transform(augment_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b91919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "def compute_metrics(eval_pred) -> Dict:\n",
    "    \"\"\"\n",
    "    Computes evaluation metrics for the image classification task.\n",
    "\n",
    "    Args:\n",
    "        eval_pred: The prediction and reference from the Trainer.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing the evaluation metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predictions, references = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "        return evaluate.load(\"accuracy\").compute(predictions=predictions, references=references)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error computing metrics: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def load_model(model_name: str) -> AutoModelForImageClassification:\n",
    "    \"\"\"\n",
    "    Loads the pre-trained image classification model.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the pre-trained model.\n",
    "\n",
    "    Returns:\n",
    "        AutoModelForImageClassification: The pre-trained model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=len(food.labels),\n",
    "            id2label=food.id2label,\n",
    "            label2id=food.label2id\n",
    "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training_arguments(output_dir: str) -> TrainingArguments:\n",
    "    \"\"\"\n",
    "    Sets the TrainingArguments object.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): The directory to save the trained model.\n",
    "\n",
    "    Returns:\n",
    "        TrainingArguments: The TrainingArguments object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            remove_unused_columns=False,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            gradient_accumulation_steps=4,\n",
    "            # num_train_epochs=2,\n",
    "            max_steps=20,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "        return args\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error setting training arguments: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "def create_model(model: AutoModelForImageClassification, args: TrainingArguments) -> Trainer:\n",
    "    \"\"\"\n",
    "    Trains the image classification model.\n",
    "\n",
    "    Args:\n",
    "        model (AutoModelForImageClassification): The pre-trained model.\n",
    "        args (TrainingArguments): The TrainingArguments object.\n",
    "\n",
    "    Returns:\n",
    "        Trainer: The trained Trainer object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=food_augment[\"train\"],\n",
    "            eval_dataset=food_augment[\"test\"],\n",
    "            tokenizer=food.image_processor,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        return trainer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error training model: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e514fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(save_name: str):\n",
    "    \"\"\"\n",
    "    Orchestrates the food classification training process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = load_model(config[\"base_model\"])\n",
    "        args = set_training_arguments(config[\"output_path\"])\n",
    "\n",
    "        trainer = create_model(model, args)\n",
    "        trainer.train()\n",
    "\n",
    "        trainer.save_model(config[\"output_path\"] + \"\\\\\" + save_name)\n",
    "        logger.info(\n",
    "            f\"Training completed. Model saved to {config[\"output_path\"]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b55861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path: str, load_name: str) -> list[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Returns image predictions.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path of custom image.\n",
    "        load_name: Name of the saved model.\n",
    "    \"\"\"\n",
    "    pipe = pipeline(\"image-classification\", config[\"output_path\"] + \"\\\\\" + load_name,\n",
    "                    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    image = Image.open(image_path)\n",
    "    return pipe(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
